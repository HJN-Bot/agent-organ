# Agent Organ v2｜现实世界的多头注意力输出系统（基于 VisionClaw × OpenClaw）

> 版本：v2.0
> 日期：2026-02-09
> 目标：把我们的 brainstorm 收敛成“可实验 / 可开发 / 可参赛交付”的一份说明。

---

## 0) 一句话（你要对外讲的版本）

**Agent Organ Hub**：把 OpenClaw 从手机里“长出来”——用 VisionClaw 式的实时语音+视觉感知，生成可执行意图；再用 OpenClaw 去完成真实世界动作；最终通过声/光/屏/设备动作构成“多头注意力”的空间化交付。

> 主线：**A（多模态输入 + 多通道输出 + L1/L2/L3分层）**
> 加分：工作场景的“质控/总控回放”（不做复杂自治，只做可回放的对齐摘要）。

---

## 1) 总体目标与两类场景（生活 × 医疗）

### 1.1 生活场景（个人效率与陪伴感）
- 核心目标：减少遗漏、降低确认成本、让空间产生“存在感”反馈
- 典型动作：记事→待办→日程→提醒→家居场景联动（灯光/音箱/空调/插座）

### 1.2 医疗场景（更严肃的“质控与审计”）
- 核心目标：**低干扰记录 + 可审计回放 + 风险分级**（更像“质控系统”而不是“炫技助手”）
- 典型动作：现场采集（按键触发）→结构化事件→生成记录/清单→提醒与升级→审计链路

> 医疗场景强调：权限/RBAC、留痕、撤销窗口、默认最小采集、本地优先。

---

## 2) 概念框架：物理世界的“多头注意力”输出系统（工程版）

### 2.1 三件套：Orchestrator / Heads / Bus
- **Orchestrator（总控大脑）**：OpenClaw + 策略层
  - 决定：何时输出、输出到哪些 head、强度多大、需不需要确认
- **Heads（多头输出代理）**：每个 head 是一个输出通道/设备簇
  - Voice Head（TTS）、Light Head（灯光）、Screen Head（卡片/大屏）、Action Head（家居动作）
- **Bus（总线/中枢）**：Home Assistant / Matter / MQTT（三选一先定）
  - 负责把抽象指令映射到具体品牌/协议

> 收敛原则：MVP 阶段 **head 是“通道”，不是“每个家具一个AI智能体”**。否则复杂度爆炸。

### 2.2 输出多元化三层
- **情感陪伴层**：氛围与低打扰反馈（灯光/短语音/提示音）
- **指导与教学层**：把“下一步”拆到可执行步骤（语音/卡片/可选AR）
- **硬件/场景层**：把抽象意图变成现实动作（scene 比单设备指令更稳）

---

## 3) 技术方案（借鉴 VisionClaw 的可复用骨架）

### 3.1 VisionClaw 给我们的关键启发
- **实时对话不是 STT→LLM→TTS**：而是原生音频双向流（在场感强）
- **视觉上下文不需要高帧率**：~1fps 就足够补全语境（稳定、成本低）
- **工具调用只暴露一个 execute**：把复杂执行交给 OpenClaw（iOS 端只做桥接）

### 3.2 端到端数据流（感知→执行→空间化交付）
1) 设备输入（眼镜/手机）：音频 + 低帧率图像
2) Gemini Live：实时理解/对话 + 生成 tool call（execute）
3) iOS Bridge：把 execute(task) 透传给 OpenClaw Gateway（/v1/chat/completions）
4) OpenClaw：调用 skills 执行（消息/搜索/日程/家居控制等）
5) 多头输出：Voice/Light/Screen/Action 同步反馈

---

## 4) L1/L2/L3 自主分层（避免“越过人代替人”）

- **L1 自动记录（默认）**：捕获→结构化→入库（不执行、不外发）
- **L2 建议输出（默认）**：给 1-3 个下一步/草稿，用户一键确认
- **L3 白名单自动执行（可选）**：仅低风险动作自动做（建提醒/建日程/写入表格/切换家居 scene），可撤销、可审计

---

## 5) 两个核心 Demo 场景（可交付版本）

### S1 生活｜“回家/专注”场景（空间响应）
- 触发：你说“我想专注/我有点累/我冷”
- 多头输出：
  - Light Head：切换 scene（focus/relax）
  - Voice Head：播报 Top1 + 下一步（≤15s）
  - Action Head：空调/插座做一个动作（升温/开加湿器/开插座）
  - Screen Head（可选）：卡片显示 checklist

### S2 医疗｜“现场记录 + 质控回放”
- 触发：按键触发短录音/拍照（push-to-record/capture）
- 输出：生成结构化事件（时间/地点/风险/行动项）+ 可回放 trace
- 质控：后续在总控中枢汇总为“待确认点/风险点/行动项”，可审计、可撤销

---

## 6) 隐私与社会接受度（必须先讲清楚）

MVP Privacy by Design（最低基线）：
- 默认不连续采集；**按键采集**（push-to-record/capture）
- **不可关闭的外部指示灯**（录音/录像/上传分状态）+ 声/振提示
- 本地优先：默认只上传事件元数据；原始音视频需二次确认
- 可撤回窗口（误触友好）
- 审计与回放：采集开始/结束、触发方式、是否上传、访问者留痕
- 数据保护：加密、最短留存、一键清除/远程擦除

工作场景红线：不做隐形监控；会议/客户现场默认禁用（除非明确同意）；访问必须审批+审计。

---

## 7) 48h 收敛版里程碑（参赛可用）

- T+6h：语音/拍照触发 → event 上报成功（可见日志/trace）
- T+12h：OpenClaw 执行一个真实动作（写入任务/日程/消息之一）
- T+18h：Voice Head（TTS）+ Light Head（灯光）闭环反馈
- T+24h：L2 一键确认（确认/延后/忽略）
- T+36h：接入 Bus（Home Assistant/MQTT/Matter）控制一个设备（Action Head）
- T+48h：两场景 demo + 一页架构图 + 隐私边界话术

---

## 8) 关键质疑点（路演答法）

- “手机够了，为什么硬件？”→ 先手机闭环验证；硬件用于把确认成本降到 1–3 秒并增强空间化陪伴
- “会不会提醒轰炸？”→ 打扰预算 + 升级策略（少提醒、更准）
- “隐私太敏感？”→ 按键采集 + 强指示灯 + 本地优先 + 审计回放 + 可撤销
- “LLM 不可靠怎么办？”→ 高风险强确认；低风险白名单自动化；每次动作有因果链与回滚

---

## 9) 下一步（待你确认的两个选择）

1) 生活场景优先空间：书桌 / 卧室 / 客厅（选一个）
2) 输出端 Top3 设备：灯 / 空调 / 插座 / 音箱 / 加湿器（选三个）

确认后就能把 skill 接口与 scene 定义写死，并进入实现。
